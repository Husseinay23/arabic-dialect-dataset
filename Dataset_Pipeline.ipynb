{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3228a6a1",
   "metadata": {},
   "source": [
    "# ğŸ“˜ Arabic Dialect Dataset: Sample Creation Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e711ca9",
   "metadata": {},
   "source": [
    "This notebook builds a speech dataset from YouTube videos using the following steps:\n",
    "\n",
    "YouTube Audio Download\n",
    "â†’ Using yt-dlp to extract .mp3 audio from videos.\n",
    "\n",
    "Audio Preparation\n",
    "â†’ Converted to mono, downsampled to 16kHz, trimmed to 30 minutes max.\n",
    "\n",
    "Voice Detection\n",
    "â†’ WebRTC VAD detects 7-second segments with human voice + 500ms padding.\n",
    "\n",
    "Segment Filtering\n",
    "â†’ Segments must be at least 7 seconds long.\n",
    "\n",
    "Normalization + Bandpass Filtering\n",
    "â†’ Audio is normalized to -20 dBFS and filtered between 300â€“3400 Hz.\n",
    "\n",
    "Transcription with Whisper\n",
    "â†’ Whisper (base) transcribes Arabic speech and estimates quality.\n",
    "\n",
    "Metadata Creation\n",
    "â†’ Each .wav sample includes:\n",
    "\n",
    "sample_id\n",
    "\n",
    "filename\n",
    "\n",
    "dialect\n",
    "\n",
    "duration\n",
    "\n",
    "start_time_ms & end_time_ms\n",
    "\n",
    "transcription\n",
    "\n",
    "avg_logprob (transcription confidence)\n",
    "\n",
    "Multi-link Support\n",
    "â†’ Pass 2â€“3 YouTube links per dialect to get diverse speakers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9022460-2515-4938-b94a-c0d8702f1e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Loading Whisper model: base...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# LOAD WHISPER MODEL ONCE\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     29\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mğŸ§  Loading Whisper model: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mWHISPER_MODEL_SIZE\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m model = \u001b[43mwhisper\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mWHISPER_MODEL_SIZE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# Download YouTube Audio\u001b[39;00m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# ---------------------------\u001b[39;00m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdownload_youtube_audio\u001b[39m(youtube_url, output_dir, filename=\u001b[33m\"\u001b[39m\u001b[33mfull_audio.mp3\u001b[39m\u001b[33m\"\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/dataset/venv/lib/python3.11/site-packages/whisper/__init__.py:159\u001b[39m, in \u001b[36mload_model\u001b[39m\u001b[34m(name, device, download_root, in_memory)\u001b[39m\n\u001b[32m    156\u001b[39m model.load_state_dict(checkpoint[\u001b[33m\"\u001b[39m\u001b[33mmodel_state_dict\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m alignment_heads \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_alignment_heads\u001b[49m\u001b[43m(\u001b[49m\u001b[43malignment_heads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m model.to(device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/dataset/venv/lib/python3.11/site-packages/whisper/model.py:282\u001b[39m, in \u001b[36mWhisper.set_alignment_heads\u001b[39m\u001b[34m(self, dump)\u001b[39m\n\u001b[32m    278\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mset_alignment_heads\u001b[39m(\u001b[38;5;28mself\u001b[39m, dump: \u001b[38;5;28mbytes\u001b[39m):\n\u001b[32m    279\u001b[39m     array = np.frombuffer(\n\u001b[32m    280\u001b[39m         gzip.decompress(base64.b85decode(dump)), dtype=\u001b[38;5;28mbool\u001b[39m\n\u001b[32m    281\u001b[39m     ).copy()\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m     mask = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m.reshape(\n\u001b[32m    283\u001b[39m         \u001b[38;5;28mself\u001b[39m.dims.n_text_layer, \u001b[38;5;28mself\u001b[39m.dims.n_text_head\n\u001b[32m    284\u001b[39m     )\n\u001b[32m    285\u001b[39m     \u001b[38;5;28mself\u001b[39m.register_buffer(\u001b[33m\"\u001b[39m\u001b[33malignment_heads\u001b[39m\u001b[33m\"\u001b[39m, mask.to_sparse(), persistent=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mRuntimeError\u001b[39m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# Sample Creation Pipeline\n",
    "import os\n",
    "import random\n",
    "import uuid\n",
    "import csv\n",
    "import subprocess\n",
    "from pytube import YouTube\n",
    "from pydub import AudioSegment\n",
    "import webrtcvad\n",
    "import whisper\n",
    "\n",
    "# ---------------------------\n",
    "# CONFIGURATION\n",
    "# ---------------------------\n",
    "CHUNK_DURATION_MS = 7000                   # Desired chunk length\n",
    "SILENCE_THRESHOLD_DB = -40                 # Unused, but reserved for silence logic\n",
    "VAD_MODE = 2                               # WebRTC VAD aggressiveness (0 = loose, 3 = strict)\n",
    "TARGET_DBFS = -20.0                        # Normalize loudness\n",
    "SAMPLE_RATE = 16000                        # Audio sample rate (Hz)\n",
    "CHANNELS = 1                               # Mono channel\n",
    "PADDING_MS = 500                           # Padding before/after detected speech (ms)\n",
    "MAX_AUDIO_DURATION_MIN = 30                # Cap audio length to first 30 minutes\n",
    "WHISPER_MODEL_SIZE = \"base\"                # Whisper model size (\"base\", \"small\", \"medium\")\n",
    "OUTPUT_BASE = \"./Dataset\"                  # Base output directory\n",
    "\n",
    "# ---------------------------\n",
    "# LOAD WHISPER MODEL ONCE\n",
    "# ---------------------------\n",
    "print(f\"ğŸ§  Loading Whisper model: {WHISPER_MODEL_SIZE}...\")\n",
    "model = whisper.load_model(WHISPER_MODEL_SIZE)\n",
    "\n",
    "# ---------------------------\n",
    "# Download YouTube Audio\n",
    "# ---------------------------\n",
    "def download_youtube_audio(youtube_url, output_dir, filename=\"full_audio.mp3\"):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "    print(f\"ğŸ”½ Downloading audio from YouTube: {youtube_url}\")\n",
    "    command = [\n",
    "        \"yt-dlp\", \"-x\", \"--audio-format\", \"mp3\",\n",
    "        \"--output\", output_path, youtube_url\n",
    "    ]\n",
    "\n",
    "    subprocess.run(command, check=True)\n",
    "    print(f\"ğŸ§ Audio downloaded and saved to {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "# ---------------------------\n",
    "# Prepare and Trim Audio\n",
    "# ---------------------------\n",
    "def prepare_audio(input_path):\n",
    "    print(\"ğŸšï¸  Preparing audio (mono + 16kHz)...\")\n",
    "    audio = AudioSegment.from_file(input_path)\n",
    "    audio = audio.set_channels(CHANNELS).set_frame_rate(SAMPLE_RATE)\n",
    "\n",
    "    max_duration_ms = MAX_AUDIO_DURATION_MIN * 60 * 1000\n",
    "    if len(audio) > max_duration_ms:\n",
    "        print(\"â±ï¸ Trimming audio to 30 minutes max\")\n",
    "        return audio[:max_duration_ms]\n",
    "    return audio\n",
    "\n",
    "# ---------------------------\n",
    "# Normalize audio volume\n",
    "# ---------------------------\n",
    "def normalize_audio(audio_segment, target_dBFS=TARGET_DBFS):\n",
    "    change = target_dBFS - audio_segment.dBFS\n",
    "    return audio_segment.apply_gain(change)\n",
    "\n",
    "# ---------------------------\n",
    "# Slice audio into raw frames for VAD\n",
    "# ---------------------------\n",
    "def make_frames(audio_segment, sample_rate, frame_duration_ms):\n",
    "    frame_len = int(sample_rate * frame_duration_ms / 1000.0) * 2\n",
    "    audio_bytes = audio_segment.raw_data\n",
    "    frames = []\n",
    "    for i in range(0, len(audio_bytes), frame_len):\n",
    "        frame = audio_bytes[i:i + frame_len]\n",
    "        if len(frame) == frame_len:\n",
    "            timestamp = int(i / (sample_rate * 2) * 1000)\n",
    "            frames.append((timestamp, frame))\n",
    "    return frames\n",
    "\n",
    "# ---------------------------\n",
    "# Detect voiced segments with WebRTC VAD\n",
    "# ---------------------------\n",
    "def vad_collector(audio_segment, sample_rate=SAMPLE_RATE, chunk_ms=30, vad_mode=VAD_MODE):\n",
    "    print(\"ğŸ—£ï¸  Detecting voiced segments using WebRTC VAD...\")\n",
    "    vad = webrtcvad.Vad(vad_mode)\n",
    "    frames = make_frames(audio_segment, sample_rate, chunk_ms)\n",
    "    segments = []\n",
    "    voiced = []\n",
    "\n",
    "    for i, (timestamp, frame) in enumerate(frames):\n",
    "        is_speech = vad.is_speech(frame, sample_rate)\n",
    "        if is_speech:\n",
    "            voiced.append((timestamp, frame))\n",
    "        elif voiced:\n",
    "            start_ms = frames[i - len(voiced)][0]\n",
    "            end_ms = timestamp\n",
    "\n",
    "            # Apply padding around detected speech\n",
    "            chunk_start = max(0, start_ms - PADDING_MS)\n",
    "            chunk_end = min(len(audio_segment), end_ms + PADDING_MS)\n",
    "            chunk = audio_segment[chunk_start:chunk_end]\n",
    "\n",
    "            if len(chunk) >= CHUNK_DURATION_MS:\n",
    "                segments.append((chunk[:CHUNK_DURATION_MS], chunk_start, chunk_end))\n",
    "                print(f\"ğŸ™ï¸  Segment extracted: {chunk_start}ms â†’ {chunk_end}ms\")\n",
    "\n",
    "            voiced = []\n",
    "\n",
    "    print(f\"âœ… VAD found {len(segments)} voiced segments\")\n",
    "    return segments\n",
    "\n",
    "# ---------------------------\n",
    "# Transcribe segments and write to metadata\n",
    "# ---------------------------\n",
    "def transcribe_and_save(segments, output_dir, dialect, source_url, quota=100):\n",
    "    print(f\"ğŸ“ Transcribing and saving segments for dialect: {dialect}\")\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    metadata_path = os.path.join(output_dir, f\"{dialect}_metadata.csv\")\n",
    "\n",
    "    with open(metadata_path, mode='w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\n",
    "            \"sample_id\", \"filename\", \"dialect\", \"duration\", \"source_url\",\n",
    "            \"start_time_ms\", \"end_time_ms\", \"language\", \"avg_logprob\",\n",
    "            \"transcription\", \"whisper_model\"\n",
    "        ])\n",
    "\n",
    "        count = 0\n",
    "        random.shuffle(segments)\n",
    "\n",
    "        for seg, start, end in segments:\n",
    "            if count >= quota:\n",
    "                break\n",
    "            \n",
    "            seg = seg.low_pass_filter(3400).high_pass_filter(300)  # âœ… Bandpass filtering\n",
    "            seg = normalize_audio(seg)\n",
    "\n",
    "\n",
    "            seg = normalize_audio(seg)\n",
    "            temp_path = os.path.join(output_dir, \"temp.wav\")\n",
    "            seg.export(temp_path, format=\"wav\")\n",
    "\n",
    "            result = model.transcribe(temp_path, language=\"ar\", fp16=False)\n",
    "            transcript = result[\"text\"].strip()\n",
    "            language = result.get(\"language\", \"\")\n",
    "            avg_logprob = result.get(\"avg_logprob\", -10.0)\n",
    "\n",
    "            if transcript and language == \"ar\" and avg_logprob > -1.0:\n",
    "                filename = f\"{dialect}_chunk_{uuid.uuid4().hex[:8]}.wav\"\n",
    "                final_path = os.path.join(output_dir, filename)\n",
    "                seg.export(final_path, format=\"wav\")\n",
    "\n",
    "                sample_id = uuid.uuid4().hex[:12]\n",
    "                writer.writerow([\n",
    "                    sample_id, filename, dialect, round(seg.duration_seconds, 2),\n",
    "                    source_url, start, end, language, round(avg_logprob, 3),\n",
    "                    transcript, WHISPER_MODEL_SIZE\n",
    "                ])\n",
    "                print(f\"âœ… [{count+1}] Saved: {filename} | ğŸ—£ï¸ {transcript}\")\n",
    "                count += 1\n",
    "            else:\n",
    "                print(\"âŒ Skipped low-quality or non-Arabic sample\")\n",
    "\n",
    "        if os.path.exists(temp_path):\n",
    "            os.remove(temp_path)\n",
    "\n",
    "    print(f\"ğŸ“ Metadata written to: {metadata_path}\")\n",
    "    print(f\"ğŸ‰ Total usable segments saved: {count}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "# ---------------------------\n",
    "# Main pipeline: Multiple videos per dialect\n",
    "# ---------------------------\n",
    "\n",
    "def process_multiple_youtube_links(dialect, links, quota=10):\n",
    "    print(f\"\\nğŸŒ Starting dataset build for: {dialect}\")\n",
    "    dialect_dir = os.path.join(OUTPUT_BASE, dialect)\n",
    "    os.makedirs(dialect_dir, exist_ok=True)\n",
    "\n",
    "    all_segments = []\n",
    "    quota_per_link = int(quota * 1.5)  # Over-sample to filter later\n",
    "\n",
    "    for i, url in enumerate(links):\n",
    "        print(f\"\\nğŸ”— Processing video {i+1}/{len(links)}: {url}\")\n",
    "        try:\n",
    "            audio_path = download_youtube_audio(url, dialect_dir, f\"audio_{i+1}.mp3\")\n",
    "            audio = prepare_audio(audio_path)\n",
    "            segments = vad_collector(audio)\n",
    "            for seg in segments:\n",
    "                all_segments.append((*seg, url))  # Include source URL\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error with link {url} â€” {e}\")\n",
    "            continue\n",
    "\n",
    "    if not all_segments:\n",
    "        print(f\"âŒ No valid segments found for {dialect}\")\n",
    "        return\n",
    "\n",
    "    print(f\"ğŸ§® Total segments collected: {len(all_segments)}\")\n",
    "    selected_segments = all_segments[:quota * 2]\n",
    "\n",
    "    # Remove URL from tuple for transcription\n",
    "    final_segments = [(seg, start, end) for seg, start, end, _ in selected_segments]\n",
    "\n",
    "    transcribe_and_save(final_segments, dialect_dir, dialect, source_url=\"multiple\", quota=quota)\n",
    "    print(f\"ğŸ Finished dialect: {dialect}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a020914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai-whisper\n",
      "  Using cached openai_whisper-20250625-py3-none-any.whl\n",
      "Collecting more-itertools (from openai-whisper)\n",
      "  Using cached more_itertools-10.7.0-py3-none-any.whl.metadata (37 kB)\n",
      "Collecting numba (from openai-whisper)\n",
      "  Using cached numba-0.61.2-cp311-cp311-macosx_10_14_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting numpy (from openai-whisper)\n",
      "  Using cached numpy-2.3.1-cp311-cp311-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Collecting tiktoken (from openai-whisper)\n",
      "  Using cached tiktoken-0.9.0-cp311-cp311-macosx_10_12_x86_64.whl.metadata (6.7 kB)\n",
      "Collecting torch (from openai-whisper)\n",
      "  Using cached torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting tqdm (from openai-whisper)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting llvmlite<0.45,>=0.44.0dev0 (from numba->openai-whisper)\n",
      "  Using cached llvmlite-0.44.0-cp311-cp311-macosx_10_14_x86_64.whl.metadata (4.8 kB)\n",
      "Collecting numpy (from openai-whisper)\n",
      "  Using cached numpy-2.2.6-cp311-cp311-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken->openai-whisper)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-macosx_10_9_x86_64.whl.metadata (40 kB)\n",
      "Collecting requests>=2.26.0 (from tiktoken->openai-whisper)\n",
      "  Using cached requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.26.0->tiktoken->openai-whisper)\n",
      "  Using cached charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (35 kB)\n",
      "Collecting idna<4,>=2.5 (from requests>=2.26.0->tiktoken->openai-whisper)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken->openai-whisper)\n",
      "  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests>=2.26.0->tiktoken->openai-whisper)\n",
      "  Using cached certifi-2025.6.15-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting filelock (from torch->openai-whisper)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch->openai-whisper)\n",
      "  Downloading typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch->openai-whisper)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch->openai-whisper)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch->openai-whisper)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch->openai-whisper)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch->openai-whisper)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (4.0 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch->openai-whisper)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached more_itertools-10.7.0-py3-none-any.whl (65 kB)\n",
      "Using cached numba-0.61.2-cp311-cp311-macosx_10_14_x86_64.whl (2.8 MB)\n",
      "Using cached llvmlite-0.44.0-cp311-cp311-macosx_10_14_x86_64.whl (28.1 MB)\n",
      "Using cached numpy-2.2.6-cp311-cp311-macosx_14_0_x86_64.whl (6.9 MB)\n",
      "Using cached tiktoken-0.9.0-cp311-cp311-macosx_10_12_x86_64.whl (1.1 MB)\n",
      "Using cached regex-2024.11.6-cp311-cp311-macosx_10_9_x86_64.whl (287 kB)\n",
      "Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Using cached charset_normalizer-3.4.2-cp311-cp311-macosx_10_9_universal2.whl (198 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached certifi-2025.6.15-py3-none-any.whl (157 kB)\n",
      "Using cached torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "Downloading typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_10_9_universal2.whl (14 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: mpmath, urllib3, typing-extensions, tqdm, sympy, regex, numpy, networkx, more-itertools, MarkupSafe, llvmlite, idna, fsspec, filelock, charset_normalizer, certifi, requests, numba, jinja2, torch, tiktoken, openai-whisper\n",
      "\u001b[2K  Attempting uninstall: mpmath\n",
      "\u001b[2K    Found existing installation: mpmath 1.3.0\n",
      "\u001b[2K    Uninstalling mpmath-1.3.0:\n",
      "\u001b[2K      Successfully uninstalled mpmath-1.3.0\n",
      "\u001b[2K  Attempting uninstall: urllib3â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 0/22\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: urllib3 2.5.00m \u001b[32m 0/22\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling urllib3-2.5.0:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/22\u001b[0m [urllib3]\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.5.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/22\u001b[0m [urllib3]\n",
      "\u001b[2K  Attempting uninstall: typing-extensionsâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/22\u001b[0m [urllib3]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.14.0â”â”â”â”â”\u001b[0m \u001b[32m 1/22\u001b[0m [urllib3]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.14.0:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/22\u001b[0m [urllib3]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.14.0â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/22\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: tqdm0mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/22\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: tqdm 4.67.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/22\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling tqdm-4.67.1:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/22\u001b[0m [typing-extensions]\n",
      "\u001b[2K      Successfully uninstalled tqdm-4.67.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/22\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: sympy90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/22\u001b[0m [tqdm]tensions]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/22\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/22\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/22\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: regex\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/22\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: regex 2024.11.6â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/22\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling regex-2024.11.6:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/22\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled regex-2024.11.6â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/22\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: numpy0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/22\u001b[0m [regex]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/22\u001b[0m [regex]\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/22\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/22\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: networkx\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/22\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: networkx 3.5â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/22\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling networkx-3.5:\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/22\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled networkx-3.5â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/22\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: more-itertoolsmâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/22\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: more-itertools 10.7.0â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/22\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling more-itertools-10.7.0:â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/22\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled more-itertools-10.7.0â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/22\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: MarkupSafe0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/22\u001b[0m [more-itertools]\n",
      "\u001b[2K    Found existing installation: MarkupSafe 3.0.2â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/22\u001b[0m [more-itertools]\n",
      "\u001b[2K    Uninstalling MarkupSafe-3.0.2:90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/22\u001b[0m [more-itertools]\n",
      "\u001b[2K      Successfully uninstalled MarkupSafe-3.0.2â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/22\u001b[0m [more-itertools]\n",
      "\u001b[2K  Attempting uninstall: llvmlite\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/22\u001b[0m [more-itertools]\n",
      "\u001b[2K    Found existing installation: llvmlite 0.44.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/22\u001b[0m [more-itertools]\n",
      "\u001b[2K    Uninstalling llvmlite-0.44.0:[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/22\u001b[0m [more-itertools]\n",
      "\u001b[2K      Successfully uninstalled llvmlite-0.44.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/22\u001b[0m [more-itertools]\n",
      "\u001b[2K  Attempting uninstall: idna0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/22\u001b[0m [llvmlite]s]\n",
      "\u001b[2K    Found existing installation: idna 3.10â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/22\u001b[0m [llvmlite]\n",
      "\u001b[2K    Uninstalling idna-3.10:[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/22\u001b[0m [llvmlite]\n",
      "\u001b[2K      Successfully uninstalled idna-3.10mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/22\u001b[0m [llvmlite]\n",
      "\u001b[2K  Attempting uninstall: fsspec0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11/22\u001b[0m [idna]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.5.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11/22\u001b[0m [idna]\n",
      "\u001b[2K    Uninstalling fsspec-2025.5.1:â•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11/22\u001b[0m [idna]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.5.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11/22\u001b[0m [idna]\n",
      "\u001b[2K  Attempting uninstall: filelockm\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12/22\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: filelock 3.18.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12/22\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling filelock-3.18.0:mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12/22\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled filelock-3.18.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12/22\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: charset_normalizer[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13/22\u001b[0m [filelock]\n",
      "\u001b[2K    Found existing installation: charset-normalizer 3.4.2â”â”â”â”â”\u001b[0m \u001b[32m13/22\u001b[0m [filelock]\n",
      "\u001b[2K    Uninstalling charset-normalizer-3.4.2:[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13/22\u001b[0m [filelock]\n",
      "\u001b[2K      Successfully uninstalled charset-normalizer-3.4.2â”â”â”â”â”â”â”\u001b[0m \u001b[32m13/22\u001b[0m [filelock]\n",
      "\u001b[2K  Attempting uninstall: certifiâ”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14/22\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: certifi 2025.6.15â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14/22\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling certifi-2025.6.15:90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14/22\u001b[0m [charset_normalizer]\n",
      "\u001b[2K      Successfully uninstalled certifi-2025.6.15â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14/22\u001b[0m [charset_normalizer]\n",
      "\u001b[2K  Attempting uninstall: requestsm\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14/22\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Found existing installation: requests 2.32.4â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m14/22\u001b[0m [charset_normalizer]\n",
      "\u001b[2K    Uninstalling requests-2.32.4:â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/22\u001b[0m [requests]lizer]\n",
      "\u001b[2K      Successfully uninstalled requests-2.32.4m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/22\u001b[0m [requests]\n",
      "\u001b[2K  Attempting uninstall: numbaâ”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/22\u001b[0m [requests]\n",
      "\u001b[2K    Found existing installation: numba 0.61.20m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16/22\u001b[0m [requests]\n",
      "\u001b[2K    Uninstalling numba-0.61.2:â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17/22\u001b[0m [numba]\n",
      "\u001b[2K      Successfully uninstalled numba-0.61.2[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17/22\u001b[0m [numba]\n",
      "\u001b[2K  Attempting uninstall: jinja2â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17/22\u001b[0m [numba]\n",
      "\u001b[2K    Found existing installation: Jinja2 3.1.6[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m18/22\u001b[0m [jinja2]\n",
      "\u001b[2K    Uninstalling Jinja2-3.1.6:â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m18/22\u001b[0m [jinja2]\n",
      "\u001b[2K      Successfully uninstalled Jinja2-3.1.61mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m18/22\u001b[0m [jinja2]\n",
      "\u001b[2K  Attempting uninstall: torchâ”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m18/22\u001b[0m [jinja2]\n",
      "\u001b[2K    Found existing installation: torch 2.2.2mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”\u001b[0m \u001b[32m18/22\u001b[0m [jinja2]\n",
      "\u001b[2K    Uninstalling torch-2.2.2:â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m19/22\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.2.2\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m19/22\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: tiktokenâ”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m19/22\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: tiktoken 0.9.0â•¸\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m19/22\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling tiktoken-0.9.0:â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m19/22\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled tiktoken-0.9.01mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”\u001b[0m \u001b[32m19/22\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: openai-whisperâ”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”\u001b[0m \u001b[32m20/22\u001b[0m [tiktoken]\n",
      "\u001b[2K    Found existing installation: openai-whisper 2025062590mâ”â”â”\u001b[0m \u001b[32m20/22\u001b[0m [tiktoken]\n",
      "\u001b[2K    Uninstalling openai-whisper-20250625:[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”\u001b[0m \u001b[32m20/22\u001b[0m [tiktoken]\n",
      "\u001b[2K      Successfully uninstalled openai-whisper-20250625\u001b[90mâ”â”â”\u001b[0m \u001b[32m20/22\u001b[0m [tiktoken]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m22/22\u001b[0m [openai-whisper]m [openai-whisper]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-3.0.2 certifi-2025.6.15 charset_normalizer-3.4.2 filelock-3.18.0 fsspec-2025.5.1 idna-3.10 jinja2-3.1.6 llvmlite-0.44.0 more-itertools-10.7.0 mpmath-1.3.0 networkx-3.5 numba-0.61.2 numpy-2.2.6 openai-whisper-20250625 regex-2024.11.6 requests-2.32.4 sympy-1.14.0 tiktoken-0.9.0 torch-2.2.2 tqdm-4.67.1 typing-extensions-4.14.1 urllib3-2.5.0\n",
      "Collecting torch\n",
      "  Using cached torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl.metadata (25 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.17.2-cp311-cp311-macosx_10_13_x86_64.whl.metadata (6.6 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.2.2-cp311-cp311-macosx_10_13_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting typing-extensions>=4.8.0 (from torch)\n",
      "  Using cached typing_extensions-4.14.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting sympy (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch)\n",
      "  Using cached networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec (from torch)\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Using cached numpy-2.3.1-cp311-cp311-macosx_14_0_x86_64.whl.metadata (62 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Using cached pillow-11.3.0-cp311-cp311-macosx_10_10_x86_64.whl.metadata (9.0 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_10_9_universal2.whl.metadata (4.0 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Using cached torch-2.2.2-cp311-none-macosx_10_9_x86_64.whl (150.8 MB)\n",
      "Using cached torchvision-0.17.2-cp311-cp311-macosx_10_13_x86_64.whl (1.7 MB)\n",
      "Using cached torchaudio-2.2.2-cp311-cp311-macosx_10_13_x86_64.whl (3.4 MB)\n",
      "Using cached pillow-11.3.0-cp311-cp311-macosx_10_10_x86_64.whl (5.3 MB)\n",
      "Using cached typing_extensions-4.14.1-py3-none-any.whl (43 kB)\n",
      "Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached MarkupSafe-3.0.2-cp311-cp311-macosx_10_9_universal2.whl (14 kB)\n",
      "Using cached networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "Downloading numpy-2.3.1-cp311-cp311-macosx_14_0_x86_64.whl (6.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m927.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, typing-extensions, sympy, pillow, numpy, networkx, MarkupSafe, fsspec, filelock, jinja2, torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: mpmath\n",
      "\u001b[2K    Found existing installation: mpmath 1.3.0\n",
      "\u001b[2K    Uninstalling mpmath-1.3.0:\n",
      "\u001b[2K      Successfully uninstalled mpmath-1.3.0\n",
      "\u001b[2K  Attempting uninstall: typing-extensionsâ”â”â”â”â”â”â”\u001b[0m \u001b[32m 0/13\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.14.113\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.14.1:â”â”\u001b[0m \u001b[32m 0/13\u001b[0m [mpmath]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.14.1â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/13\u001b[0m [typing-extensions]\n",
      "\u001b[2K  Attempting uninstall: sympyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/13\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 1/13\u001b[0m [typing-extensions]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/13\u001b[0m [sympy]ensions]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/13\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: pillow90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/13\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: pillow 11.3.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 2/13\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling pillow-11.3.0:\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/13\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled pillow-11.3.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/13\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: numpy0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/13\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 3/13\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:â•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/13\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/13\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: networkx0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/13\u001b[0m [numpy]\n",
      "\u001b[2K    Found existing installation: networkx 3.5â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 4/13\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling networkx-3.5:0mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/13\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled networkx-3.5â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/13\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: MarkupSafe[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/13\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: MarkupSafe 3.0.2â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/13\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling MarkupSafe-3.0.2:[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/13\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled MarkupSafe-3.0.2â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 5/13\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: fsspec\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/13\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.5.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/13\u001b[0m [MarkupSafe]\n",
      "\u001b[2K    Uninstalling fsspec-2025.5.1:[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/13\u001b[0m [MarkupSafe]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.5.1â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 6/13\u001b[0m [MarkupSafe]\n",
      "\u001b[2K  Attempting uninstall: filelockm\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/13\u001b[0m [fsspec]\n",
      "\u001b[2K    Found existing installation: filelock 3.18.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/13\u001b[0m [fsspec]\n",
      "\u001b[2K    Uninstalling filelock-3.18.0:mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 7/13\u001b[0m [fsspec]\n",
      "\u001b[2K      Successfully uninstalled filelock-3.18.0\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/13\u001b[0m [filelock]\n",
      "\u001b[2K  Attempting uninstall: jinja2â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/13\u001b[0m [filelock]\n",
      "\u001b[2K    Found existing installation: Jinja2 3.1.60mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/13\u001b[0m [filelock]\n",
      "\u001b[2K    Uninstalling Jinja2-3.1.6:0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/13\u001b[0m [filelock]\n",
      "\u001b[2K      Successfully uninstalled Jinja2-3.1.6[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 8/13\u001b[0m [filelock]\n",
      "\u001b[2K  Attempting uninstall: torchâ”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/13\u001b[0m [jinja2]\n",
      "\u001b[2K    Found existing installation: torch 2.2.2m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m 9/13\u001b[0m [jinja2]\n",
      "\u001b[2K    Uninstalling torch-2.2.2:â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/13\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torch-2.2.2\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/13\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvisionâ”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10/13\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: torchvision 0.17.2\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m11/13\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling torchvision-0.17.2:â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m11/13\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.17.20m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m11/13\u001b[0m [torchvision]\n",
      "\u001b[2K  Attempting uninstall: torchaudioâ”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”\u001b[0m \u001b[32m11/13\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: torchaudio 2.2.2[91mâ•¸\u001b[0m\u001b[90mâ”â”â”\u001b[0m \u001b[32m12/13\u001b[0m [torchaudio]\n",
      "\u001b[2K    Uninstalling torchaudio-2.2.2:â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”\u001b[0m \u001b[32m12/13\u001b[0m [torchaudio]\n",
      "\u001b[2K      Successfully uninstalled torchaudio-2.2.21mâ•¸\u001b[0m\u001b[90mâ”â”â”\u001b[0m \u001b[32m12/13\u001b[0m [torchaudio]\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13/13\u001b[0m [torchaudio]3\u001b[0m [torchaudio]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "numba 0.61.2 requires numpy<2.3,>=1.24, but you have numpy 2.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 filelock-3.18.0 fsspec-2025.5.1 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-2.3.1 pillow-11.3.0 sympy-1.14.0 torch-2.2.2 torchaudio-2.2.2 torchvision-0.17.2 typing-extensions-4.14.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall openai-whisper\n",
    "!{sys.executable} -m pip install --upgrade --force-reinstall torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aabc078",
   "metadata": {},
   "source": [
    "# Links\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a966d8",
   "metadata": {},
   "source": [
    "\n",
    "This notebook contains YouTube audio collection and cleaning blocks for Arabic dialects:\n",
    "- Lebanese\n",
    "- Egyptian\n",
    "- Syrian\n",
    "- Palestinian\n",
    "- Jordanian\n",
    "- Iraqi\n",
    "- Saudi\n",
    "- Emirati\n",
    "\n",
    "Select the block for the dialect you want to process and then run the final pipeline cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36b7ab4",
   "metadata": {},
   "source": [
    "### Lebanese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a38af690-6535-4d9f-8d83-23128eed06d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dialect = \"Lebanese\"\n",
    "links = [\n",
    "    \"https://www.youtube.com/watch?v=wLZ5TkkJyzI\",\n",
    "    \"https://www.youtube.com/watch?v=QALZXfprao4\",\n",
    "    \"https://www.youtube.com/watch?v=ni0_JIhc1h4\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda39a5e",
   "metadata": {},
   "source": [
    "### Jordanian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7adfa7-3c3a-48ec-b550-32f89999be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dialect = \"Jordanian\"\n",
    "links = [\n",
    "    \"https://www.youtube.com/watch?v=wLZ5TkkJyzI\",\n",
    "    \"https://www.youtube.com/watch?v=example2\",\n",
    "    \"https://www.youtube.com/watch?v=example3\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba913d9",
   "metadata": {},
   "source": [
    "### Palestinian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f967c5-a29d-47cc-850e-43b35df42bdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dialect = \"Palestinian\"\n",
    "links = [\n",
    "    \"https://www.youtube.com/watch?v=wLZ5TkkJyzI\",\n",
    "    \"https://www.youtube.com/watch?v=example2\",\n",
    "    \"https://www.youtube.com/watch?v=example3\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f32673",
   "metadata": {},
   "source": [
    "### Syrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6b0da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialect = \"Syrian\"\n",
    "links = [\n",
    "    \"https://www.youtube.com/watch?v=wLZ5TkkJyzI\",\n",
    "    \"https://www.youtube.com/watch?v=example2\",\n",
    "    \"https://www.youtube.com/watch?v=example3\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e92a9f",
   "metadata": {},
   "source": [
    "### Saudi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd116b3-b271-46dd-88d1-5dc0cc8a9a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dialect = \"Saudi\"\n",
    "links = [\n",
    "    \"https://www.youtube.com/watch?v=wLZ5TkkJyzI\",\n",
    "    \"https://www.youtube.com/watch?v=example2\",\n",
    "    \"https://www.youtube.com/watch?v=example3\"\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75729e9f",
   "metadata": {},
   "source": [
    "### Egyptian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e0a81b-fa3d-4993-8ada-183aa670b741",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dialect = \"Egyptian\"\n",
    "links = [\n",
    "    \"https://www.youtube.com/watch?v=wLZ5TkkJyzI\",\n",
    "    \"https://www.youtube.com/watch?v=example2\",\n",
    "    \"https://www.youtube.com/watch?v=example3\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b879ee",
   "metadata": {},
   "source": [
    "### Emarati\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29939ae7-3e84-40a6-bd4f-9958379cf13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dialect = \"Emarati\"\n",
    "links = [\n",
    "    \"https://www.youtube.com/watch?v=wLZ5TkkJyzI\",\n",
    "    \"https://www.youtube.com/watch?v=example2\",\n",
    "    \"https://www.youtube.com/watch?v=example3\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2802199d",
   "metadata": {},
   "source": [
    "### Iraqi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b8248f-682c-4878-b015-e5a8de9fb10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dialect = \"Iraqi\"\n",
    "links = [\n",
    "    \"https://www.youtube.com/watch?v=wLZ5TkkJyzI\",\n",
    "    \"https://www.youtube.com/watch?v=example2\",\n",
    "    \"https://www.youtube.com/watch?v=example3\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada4cbaf",
   "metadata": {},
   "source": [
    "# Dataset Splitter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c07ee6",
   "metadata": {},
   "source": [
    "##### ğŸ”€ Dataset Splitting: Train / Validation / Test\n",
    "\n",
    "After collecting and cleaning audio samples for each dialect, we split the data into:\n",
    "- **Training set** (`train/`): used to train the model\n",
    "- **Validation set** (`val/`): used during training to check performance\n",
    "- **Test set** (`test/`): used after training to evaluate final accuracy\n",
    "\n",
    "Each split gets its own folder with:\n",
    "- Clean `.wav` audio files\n",
    "- A corresponding `mel/` folder for Mel spectrograms\n",
    "\n",
    "This process also updates the metadata file to include a new column: `\"split\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca03797-5a53-4d2b-9341-6d225763dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_dataset(dialect_dir, dialect, test_size=0.15, val_size=0.15):\n",
    "    print(f\"ğŸ“‚ Splitting dataset for: {dialect}\")\n",
    "\n",
    "    df = pd.read_csv(f\"{dialect_dir}/{dialect}_metadata.csv\")\n",
    "\n",
    "    train_val, test = train_test_split(df, test_size=test_size, random_state=42)\n",
    "    train, val = train_test_split(train_val, test_size=val_size/(1-test_size), random_state=42)\n",
    "\n",
    "    df['split'] = 'train'\n",
    "    df.loc[val.index, 'split'] = 'val'\n",
    "    df.loc[test.index, 'split'] = 'test'\n",
    "\n",
    "    # Create folders\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for sub in ['wav', 'mel']:\n",
    "            os.makedirs(os.path.join(dialect_dir, split, sub), exist_ok=True)\n",
    "\n",
    "    # Move files to new folders\n",
    "    for _, row in df.iterrows():\n",
    "        src = os.path.join(dialect_dir, row['filename'])\n",
    "        dst = os.path.join(dialect_dir, row['split'], 'wav', row['filename'])\n",
    "        shutil.move(src, dst)\n",
    "\n",
    "    df.to_csv(os.path.join(dialect_dir, f\"{dialect}_metadata.csv\"), index=False)\n",
    "    print(f\"âœ… Done splitting {len(df)} files into train/val/test.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7071b576",
   "metadata": {},
   "source": [
    "# ğŸ¼ Generate Mel Spectrograms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c7cf0",
   "metadata": {},
   "source": [
    "\n",
    "For each audio file, we generate a Mel spectrogram and save it as a `.png` image.\n",
    "\n",
    "This helps transform raw `.wav` files into a visual format for training CNN models.\n",
    "\n",
    "After generation:\n",
    "- Spectrograms are stored in `mel/` folders inside each split (`train`, `val`, `test`)\n",
    "- Their paths are recorded in the metadata under the `\"mel_path\"` column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4070cbc9-9216-4719-a21a-8519e48f0891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_mel_spectrograms(dialect_dir, dialect):\n",
    "    print(f\"ğŸ¼ Generating Mel spectrograms for: {dialect}\")\n",
    "    df = pd.read_csv(os.path.join(dialect_dir, f\"{dialect}_metadata.csv\"))\n",
    "    df['mel_path'] = \"\"\n",
    "\n",
    "    for i, row in df.iterrows():\n",
    "        wav_path = os.path.join(dialect_dir, row['split'], 'wav', row['filename'])\n",
    "        mel_path = os.path.join(dialect_dir, row['split'], 'mel', row['filename'].replace('.wav', '.png'))\n",
    "\n",
    "        try:\n",
    "            y, sr = librosa.load(wav_path, sr=16000)\n",
    "            mel = librosa.feature.melspectrogram(y, sr=sr, n_mels=128)\n",
    "            mel_db = librosa.power_to_db(mel, ref=np.max)\n",
    "\n",
    "            plt.figure(figsize=(3, 3))\n",
    "            librosa.display.specshow(mel_db, sr=sr, x_axis=None, y_axis=None)\n",
    "            plt.axis('off')\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(mel_path, bbox_inches='tight', pad_inches=0)\n",
    "            plt.close()\n",
    "\n",
    "            df.at[i, 'mel_path'] = mel_path\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error on {row['filename']} â†’ {e}\")\n",
    "    \n",
    "        print(f\"âœ… Mel spectrograms saved and metadata updated.\")\n",
    "\n",
    "    df.to_csv(os.path.join(dialect_dir, f\"{dialect}_metadata.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
